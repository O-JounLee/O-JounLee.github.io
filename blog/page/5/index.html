<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> blog - page 5 | O-Joun Lee </title> <meta name="author" content="O-Joun Lee"> <meta name="description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="O-Joun Lee"> <meta property="og:type" content="article"> <meta property="og:title" content="O-Joun Lee | blog - page 5"> <meta property="og:url" content="https://o-jounlee.github.io/blog/page/5/"> <meta property="og:description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="blog - page 5"> <meta name="twitter:description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "O-Joun Lee"
        },
        "url": "https://o-jounlee.github.io/blog/page/5/index.html",
        "@type": "BlogPosting",
        "description": "The academic profile of Prof. O-Joun Lee at The Catholic University of Korea
",
        "headline": "blog - page 5",
        
        "sameAs": ["https://orcid.org/0000-0001-8921-5443", "https://scholar.google.com/citations?user=43GFjoYAAAAJ", "https://www.semanticscholar.org/author/144914730", "https://www.scopus.com/authid/detail.uri?authorId=57150108800", "https://github.com/NSLab-CUK", "https://nslab-cuk.github.io/", "https://dblp.uni-trier.de/pid/160/1579.html", "https://www.kaggle.com/cuknslab"],
        
        "name": "O-Joun Lee",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://o-jounlee.github.io/blog/page/5/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">O-Joun</span> Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <div class="header-bar"> <h1>O-Joun Lee</h1> <h2>Graphs illustrate intricate patterns in our perception of the world and ourselves; graph mining enhances this comprehension by highlighting overlooked details.</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>•</p> <li> <i class="fa-solid fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <ul class="post-list"> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/11/21/WS/" target="_blank" rel="external nofollow noopener">NS-CUK Winter School on AI Ethics 2023</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <blockquote> <p>The 2nd NS-CUK Winter School on Ethics of AI and Robots</p> </blockquote> <blockquote> <p>(NS-CUK AI Ethics 2023; 2023년 가톨릭대학교 인공지능 윤리 겨울학교)</p> </blockquote> <hr> <p>NS Lab@CUK organizes a winter school dedicated to the ethics of AI and robots. This program consists of 9 lectures presented by Dr. Eun-Soon You (유은순 박사), and is scheduled to take place over a period of two weeks, from December 18th, 2023, to December 29th, 2023.</p> <p>Here are the details of the winter school:</p> <ul> <li>Location: Sophie Barat Hall B352, Songsim Global Campus, The Catholic University of Korea</li> <li>Time: Weekdays, 14:00</li> <li>TA: <a href="https://nslab-cuk.github.io/member/hbkim" rel="external nofollow noopener" target="_blank">Ho Beom Kim</a> </li> </ul> <hr> <h3 class="no_toc" id="programme-at-a-glance">Programme at a glance</h3> <details> <summary>Dec 18th, 2023: What is AI (and Robots) Ethics?</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/hMuZLcqL6UY7Ok?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 19th, 2023: AI (and Robots) Ethics Guidelines</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/4fLh3MZW0cAIx0?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 20th, 2023: Ethical Agents in Everyday Life</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/e1M5FxHiWgeS1H?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 21st, 2023: Ethical Issues of AI (and Robots): Law</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/KOrt2rHBH7YJqb?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 22nd, 2023: Ethical Issues of AI (and Robots): Art</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/ekkIuwFM3tPhdv?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 26th, 2023: Technology for Implementing Ethical AI (and Robots) I</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/9VtrvoCaVr4304?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 27th, 2023: Technology for Implementing Ethical AI (and Robots) II</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/kplgoQjZaBCSLs?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 28th, 2023: Biases in AI</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/hblzyt9msVGO23?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 29th, 2023: Applications of Ethical AI (and Robots): Medicine and Law</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/EcPphEBMgwCKVU?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <hr> <p align="center"><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/Logo_Square.png" style="width : 120px; margin : 10px"></a><a href="https://cukai.catholic.ac.kr/cukai/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/AI_Logo.png" style="width : 110px; margin : 15px"></a><a href="https://linc.catholic.ac.kr/lincplus/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/CUKLINK_Logo.jpg" style="width : 380px; margin : 10px"></a></p> <hr> <p class="post-meta"> 1 min read   ·   November 21, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/08/30/LiteralKG/" target="_blank" rel="external nofollow noopener">LiteralKG, A Novel GNN Model for Learning Literal-aware Representations of Medical Knowledge Graphs</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>We present <a href="https://github.com/NSLab-CUK/LiteralKG" rel="external nofollow noopener" target="_blank">LiteralKG</a>, a novel GNN model for learning literal-aware representations of medical knowledge graphs, which can integrate different types of literal information and graph structural features into unified vector representations. LiteralKG is developed by NS Lab, CUK, based on pure PyTorch backend.</p> <p align="center"> <img src="/images/LiteralKG.jpg" alt="LiteralKG Architecture" width="800"> <br> <b></b> The overall architecture of LiteralKG. </p> <p>Over the past few years, Knowledge Graph (KG) embedding has been used to benefit the diagnosis of animal diseases by analyzing electronic medical records (EMRs), such as notes and veterinary records. However, learning representations to capture entities and relations with literal information in KGs is challenging as the KGs show heterogeneous properties and various types of literal information. Meanwhile, the existing methods mostly aim to preserve graph structures surrounding target nodes without considering different types of literals, which could also carry significant information. We propose <strong>LiteralKG</strong>, a knowledge graph embedding model for efficiently diagnosing animal diseases, which could learn various types of literal information and graph structure and fuse them into unified representations. Specifically, we construct a knowledge graph that is built from EMRs along with literal information collected from various animal hospitals. We then fuse different types of entities and node feature information into unified vector representations through gate networks. Finally, we propose a self-supervised learning task to learn graph structure in pretext tasks and then towards various downstream tasks. Experimental results on link prediction tasks demonstrate that our model outperforms the baselines that consist of state-of-the-art models.</p> <h2 id="a-short-description-of-literalkg">A short description of <strong>LiteralKG</strong>:</h2> <ul> <li>We construct a medical knowledge graph that comprises 595,172 entities and 16 relation types from various EMRs.</li> <li> <strong>LiteralKG</strong> could learn different types of literal information and graph structure and then fuse them into unified representations.</li> <li> <strong>LiteralKG</strong>, a self-supervised learning framework for Knowledge Graph, that could learn the graph structure from pretext tasks to generate representations, and then the pre-trained model is used for downstream tasks to predict animal diseases.</li> <li>The experimental results on the KG with different types of GNN aggregators and residual connection and identity mapping show the superiority of <strong>LiteralKG</strong> over baselines.</li> </ul> <h2 id="the-literalkg-is-available-at">The <strong>LiteralKG</strong> is available at:</h2> <ul> <li><a href="https://github.com/NSLab-CUK/LiteralKG" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/GitHub-Data%20&amp;%20Code-9B9B9B?style=flat-square&amp;logo=GitHub" alt="GitHub"></a></li> <li><a href="https://doi.org/10.1109/ACCESS.2023.3324046" rel="external nofollow noopener" target="_blank"><img src="http://img.shields.io/:DOI-10.1109/ACCESS.2023.3324046-FAB70C?style=flat-square&amp;logo=doi" alt="DOI"></a></li> <li><a href="https://arxiv.org/abs/2309.03219" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/arXiv-2309.03219-b31b1b?style=flat-square&amp;logo=arxiv&amp;logoColor=red" alt="arXiv"></a></li> <li><a href="https://paperswithcode.com/paper/companion-animal-disease-diagnostics-based-on" rel="external nofollow noopener" target="_blank"><img src="https://custom-icon-badges.demolab.com/badge/Papers%20With%20Code-LiteralKG-21CBCE?style=flat-square&amp;logo=paperswithcode" alt="PWC"></a></li> </ul> <h2 id="cite-literalkg-as">Cite “<strong>LiteralKG</strong>” as:</h2> <p>Please cite our <a href="https://ieeexplore.ieee.org/abstract/document/10283810" rel="external nofollow noopener" target="_blank">paper</a> if you find <em>LiteralKG</em> useful in your work:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@Article{Hoang2023,
  author  = {Van Thuy Hoang and Thanh Sang Nguyen and Sangmyeong Lee and Jooho Lee and Luong Vuong Nguyen and O-Joun Lee},
  title   = {Companion Animal Disease Diagnostics Based on Literal-Aware Medical Knowledge Graph Representation Learning},
  journal = {IEEE Access},
  year    = {2023},
  volume  = {11},
  pages   = {114238--114249},
  month   = oct,
  issn    = {2169-3536},
  doi     = {10.1109/ACCESS.2023.3324046},
}
</code></pre></div></div> <p><img class="emoji" title=":page_facing_up:" alt=":page_facing_up:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c4.png" height="20" width="20"><img class="emoji" title=":woman_technologist:" alt=":woman_technologist:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f469-1f4bb.png" height="20" width="20"><img class="emoji" title=":bookmark_tabs:" alt=":bookmark_tabs:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d1.png" height="20" width="20"><img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"><img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20"></p> <h2 id="contributors">Contributors:</h2> <p><a href="https://github.com/NSLab-CUK/LiteralKG/graphs/contributors" rel="external nofollow noopener" target="_blank"> <img src="https://contrib.rocks/image?repo=NSLab-CUK/LiteralKG"> </a></p> <hr> <p><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img src="https://github.com/NSLab-CUK/NSLab-CUK/raw/main/Logo_Dual_Wide.png"></a></p> <hr> <p class="post-meta"> 1 min read   ·   August 30, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/08/17/UGT/" target="_blank" rel="external nofollow noopener">UGT, A Novel Graph Transformer Model for Unifying Local and Global Graph Structural Features</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>We present <a href="https://github.com/NSLab-CUK/Unified-Graph-Transformer" rel="external nofollow noopener" target="_blank">UGT</a>, a novel Graph Transformer model specialised in preserving both local and global graph structures and developed by NS Lab, CUK based on pure PyTorch backend.</p> <p align="center"> <img src="/images/UGT.jpg" alt="Graph Transformer Architecture" width="800"> <br> <b></b> The overall architecture of Unified Graph Transformer Networks. </p> <p>Over the past few years, graph neural networks and graph transformers have been successfully used to analyze graph-structured data, mainly focusing on node classification and link prediction tasks. However, the existing studies mostly only consider local connectivity while ignoring long-range connectivity and the roles of nodes. We propose Unified Graph Transformer Networks (UGT) that effectively integrate local and global structural information into fixed-length vector representations. UGT learns local structure by identifying the local substructures and aggregating features of the k-hop neighborhoods of each node. We construct virtual edges, bridging distant nodes with structural similarity to capture the long-range dependencies. UGT learns unified representations through self-attention, encoding structural distance and p-step transition probability between node pairs. Furthermore, we propose a self-supervised learning task that effectively learns transition probability to fuse local and global structural features, which could then be transferred to other downstream tasks. Experimental results on real-world benchmark datasets over various downstream tasks showed that UGT significantly outperformed baselines that consist of state-of-the-art models. In addition, UGT reaches the third-order Weisfeiler-Lehman power to distinguish non-isomorphic graph pairs.</p> <h2 id="a-short-description-of-ugt">A short description of UGT:</h2> <ul> <li>UGT could learn both local and global structural information and fuse them into unified representations.</li> <li>UGT capture the long-range dependencies between distant nodes as long as they are structurally similar. To do that, UGT constructs virtual edges, bridging the distant nodes with structural similarity.</li> <li>UGT captures local structure through structural identity in addressing local non-isomorphic substructures and finding similar ones.</li> <li>UGT, a self-supervised learning framework for graphs, that bridges the conceptual gap between local and global structural features by preserving transition probabilities between nodes in multi-scales.</li> <li>Experiments on fifteen publicly available datasets over various downstream tasks demonstrate the superiority of UGT over SOTA baselines.</li> <li>UGT reaches the third-order Weisfeiler-Lehman (3d-WL) power to distinguish non-isomorphic graph pairs.</li> </ul> <h2 id="the-ugt-is-available-at">The UGT is available at:</h2> <ul> <li><a href="https://doi.org/10.1609/aaai.v38i11.29138" rel="external nofollow noopener" target="_blank"><img src="http://img.shields.io/:DOI-10.1609/aaai.v38i11.29138-FAB70C?style=flat-square&amp;logo=doi" alt="DOI"></a></li> <li><a href="https://github.com/NSLab-CUK/Unified-Graph-Transformer" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/GitHub-Data%20&amp;%20Code-9B9B9B?style=flat-square&amp;logo=GitHub" alt="GitHub"></a></li> <li><a href="https://arxiv.org/abs/2308.09517" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/arXiv-2308.09517-b31b1b?style=flat-square&amp;logo=arxiv&amp;logoColor=red" alt="arXiv"></a></li> <li><a href="https://paperswithcode.com/paper/transitivity-preserving-graph-representation" rel="external nofollow noopener" target="_blank"><img src="https://custom-icon-badges.demolab.com/badge/Papers%20With%20Code-UGT-21CBCE?style=flat-square&amp;logo=paperswithcode" alt="PwC"></a></li> </ul> <h2 id="cite-ugt-as">Cite “UGT” as:</h2> <p>Please cite our <a href="https://arxiv.org/abs/2308.09517" rel="external nofollow noopener" target="_blank">paper</a> if you find <em>UGT</em> useful in your work:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@InProceedings{Hoang_2024,
  author    = {Hoang, Van Thuy and Lee, O-Joun},
  booktitle = {Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI 2024)},
  title     = {Transitivity-Preserving Graph Representation Learning for Bridging Local Connectivity and Role-Based Similarity},
  year      = {2024},
  address   = {Vancouver, Canada},
  editor    = {Michael Wooldridge and Jennifer Dy and Sriraam Natarajan},
  month     = feb,
  number    = {11},
  pages     = {12456--12465},
  publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
  volume    = {38},
  doi       = {10.1609/aaai.v38i11.29138},
  issn      = {2159-5399},
  url       = {https://doi.org/10.1609/aaai.v38i11.29138},
}
</code></pre></div></div> <p><img class="emoji" title=":page_facing_up:" alt=":page_facing_up:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c4.png" height="20" width="20"><img class="emoji" title=":woman_technologist:" alt=":woman_technologist:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f469-1f4bb.png" height="20" width="20"><img class="emoji" title=":bookmark_tabs:" alt=":bookmark_tabs:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d1.png" height="20" width="20"><img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"><img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20"></p> <h2 id="contributors">Contributors:</h2> <p><a href="https://github.com/NSLab-CUK/Unified-Graph-Transformer/graphs/contributors" rel="external nofollow noopener" target="_blank"> <img src="https://contrib.rocks/image?repo=NSLab-CUK/Unified-Graph-Transformer"> </a></p> <hr> <p><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img src="https://github.com/NSLab-CUK/NSLab-CUK/raw/main/Logo_Dual_Wide.png"></a></p> <hr> <p class="post-meta"> 1 min read   ·   August 17, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/08/08/Seminar/" target="_blank" rel="external nofollow noopener">2023 CUK-AICT Joint Seminar on AI</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <blockquote> <p>The 2023 CUK-AICT Joint Seminar on Artificial Intelligence</p> </blockquote> <blockquote> <p>(2023년 가톨릭대학교-차세대융합기술연구원 공동 인공지능 세미나)</p> </blockquote> <hr> <p>NS Lab@CUK and the Advanced Institute of Convergence Technology (AICT) are organizing a joint seminar focusing on diverse application domains of artificial intelligence. The seminar series features 5 presentations by AICT researchers and is scheduled for August 22nd, 2023.</p> <p>Here are the details of the joint seminar:</p> <ul> <li>Location: Seminar Hall I, Advanced Institute of Convergence Technology, 145, Gwanggyo-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, Republic of Korea</li> <li>Date &amp; Time: August 22nd, 2023, Tuesday, 09:30 AM 🕤 (Departure from CUK at 08:30 AM 🕣)</li> <li>Assistant: <a href="https://nslab-cuk.github.io/member/helee" rel="external nofollow noopener" target="_blank">Hyo Eun Lee</a> </li> </ul> <hr> <h3 id="programme-at-a-glance">Programme at a glance</h3> <ul> <li>10:00 – 11:00 - Hyungjoo Kim, Senior Researcher (김형주 선임연구원): “AI Applications in Autonomous Cooperative Driving: Current Research (인공지능 활용 자율협력주행 연구동향)”</li> <li>11:00 – 12:00 - SuJin Bak, Senior Researcher (박수진 선임연구원): “AI-powered Brain-Computer Interfaces: Current Research (인공지능 기반 뇌-컴퓨터 인터페이스 연구동향)”</li> <li>13:30 – 14:30 - Gyuwon Song, Principal Researcher (송규원 책임연구원): “Leveraging Data Science for Addressing Social Challenges (사회문제 해결을 위한 데이터과학 연구동향)”</li> <li>14:30 – 15:30 - Sungyeop Jung, Senior Researcher (정성엽 선임연구원): “Innovations in Semiconductor Design through AI (인공지능 활용 반도체 설계 연구동향)”</li> <li>15:30 – 16:30 - Lab Tour</li> </ul> <hr> <p align="center"><img src="/images/CUK-AICT-Seminar-23.jpg" style="width : 90%; max-width: 90%"></p> <hr> <p align="center"><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/Logo_Square.png" style="width : 120px; margin : 10px"></a><a href="https://cukai.catholic.ac.kr/cukai/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/AI_Logo.png" style="width : 110px; margin : 15px"></a><a href="https://linc.catholic.ac.kr/lincplus/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/CUKLINK_Logo.jpg" style="width : 380px; margin : 10px"></a></p> <hr> <p class="post-meta"> 1 min read   ·   August 08, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/08/06/Seminar/" target="_blank" rel="external nofollow noopener">2023 Fall CUK AI Seminar Series</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <blockquote> <p>The 2023 Fall CUK Artificial Intelligence Seminar Series</p> </blockquote> <blockquote> <p>(2023년 가을 가톨릭대학교 인공지능 세미나)</p> </blockquote> <hr> <p>The Department of AI at CUK is hosting a seminar series focusing on diverse application domains of artificial intelligence. Spanning 15 weeks, from August 29th, 2023, to December 5th, 2023, this series will feature 13 talks by leading experts from both the corporate world and research institutions.</p> <p>Details of the seminar series are as follows:</p> <ul> <li>Location: Sophie Barat Hall B351, Songsim Global Campus, The Catholic University of Korea</li> <li>Time: Tuesdays, 18:00</li> <li>Assistant: <a href="https://nslab-cuk.github.io/member/helee" rel="external nofollow noopener" target="_blank">Hyo Eun Lee</a> </li> </ul> <hr> <h3 id="programme-at-a-glance">Programme at a glance</h3> <ul> <li>Aug 29th, 2023 - Donghwan Kwon, Klaytn Foundation (Klaytn 재단 권동환): “What Problems is Blockchain Aiming to Solve? (블록체인이 풀고자 하는 문제는 무엇인가?)”</li> <li>Sep 05th, 2023 - Sojung An, KIAPS (차세대수치예보모델개발사업단 안소정): “Utilizing AI for Advanced Weather Forecasting and Climate Disaster Mitigation (기상예측 및 기후재난 대응을 위한 인공지능 기술의 활용)”</li> <li>Sep 12th, 2023 - Jin-Pyung Kim, Global Bridge (글로벌브릿지 김진평): “The Role of Deep Learning in Monitoring and Predicting Traffic Flow (교통흐름 모니터링 및 예측을 위한 인공지능 기술의 활용)”</li> <li>Sep 19th, 2023 - Seulgi Moon, Seung Pyung Lawfirm (법무법인 승평 문슬기): “The Intersection of Law and Artificial Intelligence (법과 AI)”</li> <li>Sep 26th, 2023 - Yongjin Park, LG Display (LG 디스플레이 박용진): “Emerging Trends of AI in Manufacturing (제조업에서의 AI 활용 현황)”</li> <li>Oct 10th, 2023 - Keun-Tae Kim, KIST (한국과학기술연구원 김근태): “Smart Interfaces Powered by Bio-signals: Moving the World with Thought (생각대로 움직이는 세상: 생체신호 기반의 지능형 인터페이스 기술)”</li> <li>Oct 24th, 2023 - Hajun Hwang, Republic of Korea Air Force (공군 황하준): “The Rise of AI in Unmanned Aerial Vehicles (무인전투기 분야에서의 AI 활용 현황)”</li> <li>Oct 31st, 2023 - Jun-Yeong Heo, Samsung Electronics (삼성전자 허준영): “AI Implementation in Samsung Electronics’ VD Division (삼성전자 VD사업부의 AI 활용 현황)”</li> <li>Nov 07th, 2023 - Minhyeok Heo, NAVER LABS (네이버랩스 허민혁): “Artificial Intelligence in Physical Spaces (오프라인 공간에서의 인공지능 기술)”</li> <li>Nov 14th, 2023 - Jae-Han Lee, Gauss Labs (가우스랩스 이재한): “Evolving Research in Anomaly Detection and Localization for Industry Applications (산업 분야에서 활용되는 이상 검출 및 지역화 기술 연구 동향과 전망)”</li> <li>Nov 21st, 2023 - Sangjin Kim, SK Hynix (SK하이닉스 김상진): “Innovations of AI in Semiconductor Manufacturing Processes (반도체 제조 공정에서의 AI활용 사례)”</li> <li>Nov 28th, 2023 - Yong-Ho Jung, Danggeun Market (당근마켓 정용호): “Danggeun Market: Revolutionizing Advertising with AI (당근마켓과 광고 AI)”</li> <li>Dec 05th, 2023 - Do-Yeun Lee, Catholic Medical Center (가톨릭중앙의료원 이도연): “Navigating Career Paths in the Hospital Sector (병원 관련 취업을 위한 진로 탐색)”</li> </ul> <hr> <h3 id="past-events">Past events</h3> <ul> <li><a href="https://nslab-cuk.github.io/2023/08/06/Seminar/" rel="external nofollow noopener" target="_blank">The 2023 Fall CUK Artificial Intelligence Seminar Series</a></li> <li><a href="https://nslab-cuk.github.io/2023/02/21/Seminar/" rel="external nofollow noopener" target="_blank">The 2023 Spring CUK Artificial Intelligence Seminar Series</a></li> </ul> <hr> <p align="center"><img src="/images/2023-2-Seminar-Poster.webp" style="width : 90%; max-width: 90%"></p> <hr> <p align="center"><a href="https://ai.catholic.ac.kr/" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/AI_Logo.png" style="width : 110px; margin : 15px"></a><a href="https://linc.catholic.ac.kr/lincplus/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/CUKLINK_Logo.jpg" style="width : 380px; margin : 10px; max-width: 90%"></a></p> <hr> <p class="post-meta"> 1 min read   ·   August 06, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/4/" tabindex="-1" aria-disabled="4">Newer</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/2/index.html" title="blog - page 2">2</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a> </li> <li class="page-item active"> <a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/6/">Older</a> </li> </ul> </nav> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 O-Joun Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Affiliated with <a href="https://nslab-cuk.github.io/" target="_blank" rel="external nofollow noopener">Network Science Lab @ CUK</a>. Last updated: April 04, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>