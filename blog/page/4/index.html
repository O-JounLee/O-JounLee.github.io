<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> blog - page 4 | O-Joun Lee </title> <meta name="author" content="O-Joun Lee"> <meta name="description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="O-Joun Lee"> <meta property="og:type" content="article"> <meta property="og:title" content="O-Joun Lee | blog - page 4"> <meta property="og:url" content="https://o-jounlee.github.io/blog/page/4/"> <meta property="og:description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="blog - page 4"> <meta name="twitter:description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "O-Joun Lee"
        },
        "url": "https://o-jounlee.github.io/blog/page/4/index.html",
        "@type": "BlogPosting",
        "description": "The academic profile of Prof. O-Joun Lee at The Catholic University of Korea
",
        "headline": "blog - page 4",
        
        "sameAs": ["https://orcid.org/0000-0001-8921-5443", "https://scholar.google.com/citations?user=43GFjoYAAAAJ", "https://www.semanticscholar.org/author/144914730", "https://www.scopus.com/authid/detail.uri?authorId=57150108800", "https://github.com/NSLab-CUK", "https://nslab-cuk.github.io/", "https://dblp.uni-trier.de/pid/160/1579.html", "https://www.kaggle.com/cuknslab"],
        
        "name": "O-Joun Lee",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://o-jounlee.github.io/blog/page/4/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">O-Joun</span> Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <div class="header-bar"> <h1>O-Joun Lee</h1> <h2>Graphs illustrate intricate patterns in our perception of the world and ourselves; graph mining enhances this comprehension by highlighting overlooked details.</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>•</p> <li> <i class="fa-solid fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <ul class="post-list"> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/12/27/ColloquiumEiR/" target="_blank" rel="external nofollow noopener">Van Thuy Hoang presented at CUK AI Colloquium 2023 and received EiR Award</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>Our team member, <a href="https://nslab-cuk.github.io/member/hoangvanthuy90" rel="external nofollow noopener" target="_blank">Van Thuy Hoang</a>, presented research outcomes for this year at <a href="https://nslab-cuk.github.io/2023/12/27/Colloquium/" rel="external nofollow noopener" target="_blank">the 2nd CUK Annual Colloquium on Artificial Intelligence (CUK AI Colloquium 2023)</a>. Also, we would like to extend our congratulations to <a href="https://nslab-cuk.github.io/member/hoangvanthuy90" rel="external nofollow noopener" target="_blank">Van Thuy Hoang</a> for winning the Exellence in Research (EiR) Award. This recognition showcases his dedication and expertise in his research progress and future plans.</p> <h4 id="van-thuy-hoang"><a href="https://nslab-cuk.github.io/member/hoangvanthuy90" rel="external nofollow noopener" target="_blank">Van Thuy Hoang</a></h4> <ul> <li>Topic: Transitivity-Preserving Graph Representation Learning for Bridging Local Connectivity and Role-based Similarity</li> <li>Abstract: We present Unified Graph Transformer Networks (UGT) that effectively integrate local and global structural information into fixed-length vector representations. First, UGT learns local structure by identifying the local substructures and aggregating features of the k-hop neighborhoods of each node. Second, we construct virtual edges, bridging distant nodes with structural similarity to capture the long-range dependencies. Third, UGT learns unified representations through self-attention, encoding structural distance and p-step transition probability between node pairs. Furthermore, we propose a self-supervised learning task that effectively learns transition probability to fuse local and global structural features, which could then be transferred to other downstream tasks. Experimental results on 21 real-world benchmark datasets over various downstream tasks showed that UGT significantly outperformed baselines that consist of state-of-the-art models. In addition, UGT reaches the third-order Weisfeiler-Lehman power to distinguish non-isomorphic graph pairs.</li> </ul> <p align="center"><img src="/images/Colloquium_2023_Hoang.webp" style="width : 90%; max-width: 90%"></p> <p class="post-meta"> 1 min read   ·   December 27, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/12/27/Colloquium/" target="_blank" rel="external nofollow noopener">CUK AI Colloquium 2023</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <blockquote> <p>The 2nd CUK Annual Colloquium on Artificial Intelligence</p> </blockquote> <blockquote> <p>(CUK AI Colloquium 2023; 제 2회 가톨릭대학교 인공지능 콜로키움)</p> </blockquote> <hr> <h2 id="aims-and-scope">Aims and Scope</h2> <p>The CUK Annual Colloquium on Artificial Intelligence is an esteemed workshop series hosted by the Department of Artificial Intelligence at the Catholic University of Korea. This event uniquely gathers both graduate and undergraduate students to showcase their research and engage in meaningful discussions with seasoned experts in the AI field. The 2023 colloquium promises a rich learning experience, featuring keynote speeches and panel discussions covering various topics. These range from career pathways in academia, industry, and entrepreneurship to cutting-edge developments in AI research.</p> <p>A highlight of the colloquium includes intensive, interactive mentoring sessions. These sessions are designed to facilitate collaborative and constructive dialogues between attendees and senior academic mentors. The focus is on research methodologies, career objectives, and fostering a vibrant, cooperative research community.</p> <hr> <h2 id="programme-in-detail">Programme in Detail</h2> <h3 id="keynote-session-1">Keynote Session 1</h3> <h4 id="prof-buru-chang-sogang-university-rep-of-korea">Prof. Buru Chang, Sogang University, Rep. of Korea</h4> <ul> <li>Topic: Mitigating Hallucination in Multimodal Language Model via Reinforcement Learning</li> <li>Abstract: 이미지와 텍스트를 함께처리할 수 있는 Multimodal Language Model이 가진 Hallucination 문제를 완화하기 위한 강화학습 프레임워크를 소개한다.</li> </ul> <p align="center"><img src="/images/231227_BR.jpg" style="width : 90%; max-width: 90%"></p> <h3 id="student-session-1">Student Session 1</h3> <h4 id="hyun-sik-won-the-catholic-university-of-korea-rep-of-korea">Hyun-Sik Won, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: EXTRA - Integrating External Knowledge into Multimodal Hashtag Recommendation</li> <li>Abstract: As microblogs have become commonplace, recommending relevant hashtags for microblog posts has become increasingly important. However, recommending appropriate hashtags for a post is challenging because it requires a high level understanding of the context and relationships of the information in the post. In this paper, we propose a novel hashtag recommendation framework that incorporates external knowledge to enrich the context of posts. Using an image of the post, we obtain the hierarchical external knowledge extracted by the Open Directory Project (ODP)-based classifier. Experimental results show that our framework performs better than the baselines on a multimodal hashtag recommendation benchmark dataset. It outperformed the existing state-of-the-art model by providing a 39.86% increase in the average F1-score.</li> </ul> <p align="center"><img src="/images/Colloquium_2023_Won.webp" style="width : 90%; max-width: 90%"></p> <h4 id="van-thuy-hoang-the-catholic-university-of-korea-rep-of-korea">Van Thuy Hoang, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Transitivity-Preserving Graph Representation Learning for Bridging Local Connectivity and Role-based Similarity</li> <li>Abstract: We present Unified Graph Transformer Networks (UGT) that effectively integrate local and global structural information into fixed-length vector representations. First, UGT learns local structure by identifying the local substructures and aggregating features of the k-hop neighborhoods of each node. Second, we construct virtual edges, bridging distant nodes with structural similarity to capture the long-range dependencies. Third, UGT learns unified representations through self-attention, encoding structural distance and p-step transition probability between node pairs. Furthermore, we propose a self-supervised learning task that effectively learns transition probability to fuse local and global structural features, which could then be transferred to other downstream tasks. Experimental results on 21 real-world benchmark datasets over various downstream tasks showed that UGT significantly outperformed baselines that consist of state-of-the-art models. In addition, UGT reaches the third-order Weisfeiler-Lehman power to distinguish non-isomorphic graph pairs.</li> </ul> <p align="center"><img src="/images/Colloquium_2023_Hoang.webp" style="width : 90%; max-width: 90%"></p> <h4 id="kyung-bin-park-and-hee-su-an-the-catholic-university-of-korea-rep-of-korea">Kyung-Bin Park and Hee-Su An, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: 지적장애 아동 대상 생체 신호 측정을 활용한 디지털 평가 프로그램 개발</li> <li>Abstract: 해당 연구는 아동의 인지 과제 수행 중에 생체신호를 측정하고 이를 통해 수행자의 지능 점수를 예측하고자 한다. 현재 널리 사용되고 있는 지능 검사를 참고하여 전체 지능 점수와 하위 지표 점수(언어이해, 시공간, 유동추론, 작업기억, 처리속도)를 파악할 수 있는 3가지 task를 제작하였다. 컴퓨터 화면에 제시된 task를 아동이 수행하는 동안 시선 데이터를 측정하고, 수집한 시선 추적 데이터를 통해 사용자의 지능 점수 예측한다. 전체 지능 점수 및 하위 지표 점수를 얻을 수 있기 때문에 개인별 특성을 반영하여 점수를 산출할 수 있다. 이렇게 시선 추적 데이터를 활용하여 아동의 지능 점수를 예측하고, 그 점수를 통해 지적 장애 위험 수준을 판단하여 조기 개입이 이루어지기 위함을 목적으로 한다.</li> </ul> <h4 id="min-ji-kim-the-catholic-university-of-korea-rep-of-korea">Min-Ji Kim, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Developing Conversational Interface for Food Service Kiosks</li> <li>Abstract: The food service industry is increasingly adopting kiosks for order placements, prompting a shift towards AI-driven conversational ordering systems. The challenge lies in efficiently training a single AI model to cater to multiple stores, as training individual models for each store is impractical due to hardware constraints. The proposed solution involves adapting the AI model to the food service domain, generating automated, store-specific datasets, and creating a Group-of-Store-Experts model that integrates multiple store experts into a single base model. This approach enables effective operation across various stores in a low-resource environment. The framework not only addresses the need for a versatile conversational interface for kiosks but also dramatically reduces GPU and memory usage during model inference, achieving an approximate 80% decrease in memory usage.</li> </ul> <p align="center"><img src="/images/Colloquium_2023_Kim.webp" style="width : 90%; max-width: 90%"></p> <h4 id="ray-kim-and-yerim-huh-the-catholic-university-of-korea-rep-of-korea">Ray Kim and Yerim Huh, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Using smart wearable ECG devices to develop deep learning-based multi-channel sleep classification technology</li> <li>Abstract: In the modern world, many people suffer from sleep deprivation due to stress, study, and work, and with the proliferation of computers and smartphones, sleep quality tends to decline. This has led to an increase in hospital visits for sleep disorders. Sleep has a significant impact on health and quality of life, and to monitor it, multi-channel biosignal-based automatic sleep stage classification devices and methods are being researched. In this paper, we propose a deep learning framework with optimal sleep stage classification performance by utilising ECG, accelerometer and gyro sensors for data-driven interpretation of sleep stages and various sampling techniques.</li> </ul> <p align="center"><img src="/images/Colloquium_2023_Ray.webp" style="width : 90%; max-width: 90%"></p> <h3 id="keynote-session-2">Keynote Session 2</h3> <h4 id="dr-kyung-rae-kim-samsung-research-rep-of-korea">Dr. Kyung-Rae Kim, Samsung Research, Rep. of Korea</h4> <ul> <li>Topic: Audio-Visual Source Separation and Source Localization</li> <li>Abstract: To achieve natural and effective human-robot interaction (HRI), robots must utilize various senses to communicate with humans. From this point of view, the robot audition sense has become increasingly important in recent years, and many studies on robot audition sense focus on sound source separation and localization. This seminar will discuss localizing and tracking specific sound sources with audio-visual information.</li> </ul> <p align="center"><img src="/images/231227_KR.jpg" style="width : 90%; max-width: 90%"></p> <h3 id="student-session-2">Student Session 2</h3> <h4 id="jae-woo-park-and-seong-ho-ahn-the-catholic-university-of-korea-rep-of-korea">Jae-Woo Park and Seong-Ho Ahn, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Motor Imagery-based Multi-Modal BCI Framework for Third-Arm Control with EEG and Eye-tracking in a Virtual Reality Environment</li> <li>Abstract: We explored the development of a brain-computer interface (BCI) framework integrating EEG and eye-tracking for controlling a virtual third arm, showcasing potential applications in immersive virtual reality settings.</li> </ul> <p align="center"><img src="/images/Colloquium_2023_Ahn.webp" style="width : 90%; max-width: 90%"></p> <h4 id="sanguk-hwang-the-catholic-university-of-korea-rep-of-korea">Sanguk Hwang, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Fit Highly Oscillatory Data with ODEs based on Neural</li> <li>Abstract: I studied the application of neural ordinary differential equations (ODEs) in modeling highly oscillatory data, demonstrating their efficacy in complex data analysis scenarios.</li> </ul> <h4 id="namrah-zaman-the-catholic-university-of-korea-rep-of-korea">Namrah Zaman, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: PETIS - Intent Classification and Slot Filling for Pet Care Services</li> <li>Abstract: PETIS is a groundbreaking dataset and framework for conversational pet care services. It tackles challenges in intent classification, slot filling, and symptom matching, offering a benchmark for research and education. The Adapter Fusion-based framework efficiently handles these tasks, providing a valuable resource for advancing pet care technology.</li> </ul> <h4 id="jinming-gao-the-catholic-university-of-korea-rep-of-korea">Jinming Gao, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Investigation in DF-VO(Depth Flow-Visual Odometry)</li> <li>Abstract: This semester I mainly studied the visual odometry system. This system mainly consists of three parts: geometry, feature point matching, and tracking. DF-VO adds Depth and Flow parts to the basic visual odometry to enhance the robustness of the visual odometry.The depth model consists of a resnet encoder and a decoder, and the decoder uses bilinear interpolation. The flow model is improved from the flownet model, and SSIM benchmark is added based on flownet.</li> </ul> <h4 id="gui-xin-wu-the-catholic-university-of-korea-rep-of-korea">Gui Xin Wu, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Research on Anomaly Detection</li> <li>Abstract: This semester I learned the basics related to artificial intelligence and also studied OmniAnomaly in the field of anomaly detection.OmniAnomaly is a robust stochastic recurrent neural network proposed for anomaly detection in complex multivariate time series data from industry devices like servers and spacecraft.</li> </ul> <h4 id="yanjun-wu-the-catholic-university-of-korea-rep-of-korea">Yanjun Wu, The Catholic University of Korea, Rep. of Korea</h4> <ul> <li>Topic: Researching HAM10000 Classification and Dependency Structures</li> <li>Abstract: I investigated the classification and analysis of the HAM10000 dataset, focusing on identifying dependency structures in skin lesion images, contributing to advancements in medical image analysis.</li> </ul> <h3 id="keynote-session-3">Keynote Session 3</h3> <h4 id="dr-jaehwan-jahng-kasan-ip-rep-of-korea">Dr. Jaehwan Jahng, Kasan IP, Rep. of Korea</h4> <ul> <li>Topic: 연구자가 알아야 할 특허 제도: 좋은 논문과 좋은 특허</li> <li>Abstract: 연구 성과를 제도적으로 보호받기 위해서는 논문 또는 학회를 통한 발표뿐만 아니라 특허 출원도 진행되어야 한다. 한편, 논문의 경우는 연구가 완성될 것을 요구하지만, 특허의 경우 당장 결과가 완성되지 않았더라도, 실현 가능성이 있는 아이디어만 있다면 출원할 수 있다. 그리고, 특허 제도의 특성상 소위 “좋은 논문”을 위한 연구를 할 때 주안점을 두어야 하는 부분과, “좋은 특허”를 위한 아이디어를 낼 때 주안점을 두어야 하는 부분은 다르다. 이번 강의에서는 특허 제도에 대한 간단한 소개와 함께, 논문을 위한 연구를 특허 출원으로 이어나가고자 할 때 유의해야 할 점들, 특히 인공지능 분야에서 학술적으로 좋은 연구 결과와 특허적으로 좋은 아이디어의 공통점과 차이점을 살펴보고자 한다.</li> </ul> <hr> <h2 id="exellence-in-research-eir-awards">Exellence in Research (EiR) Awards</h2> <p>The CUK Annual Colloquium on Artificial Intelligence acknowledges the exceptional research achievements within the Department of Artificial Intelligence at the Catholic University of Korea. The department awards the Excellence in Research (EiR) Awards to students demonstrating outstanding research performance both qualitatively and quantitatively. This year’s recipients are:</p> <ul> <li>Excellence in Research (EiR) Awards <ul> <li>Van Thuy Hoang (Ph.D. Course)</li> <li>Min-Ji Kim (Master’s Course)</li> </ul> </li> <li>Excellence in Undergraduate Research (EiR) Awards <ul> <li>Ray Kim and Yerim Huh (Undergraduate Course)</li> </ul> </li> </ul> <p align="center"><img src="/images/231227.jpg" style="width : 90%; max-width: 90%"></p> <hr> <p align="center"><a href="https://cukai.catholic.ac.kr/cukai/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/AI_Logo.png" style="width : 110px; margin : 15px"></a><a href="https://linc.catholic.ac.kr/lincplus/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/CUKLINK_Logo.jpg" style="width : 380px; margin : 10px; max-width: 90%"></a></p> <hr> <p class="post-meta"> 1 min read   ·   December 27, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/12/09/AAAI24/" target="_blank" rel="external nofollow noopener">Two NS-CUK papers accepted for AAAI'24 and XAI4Sci@AAAI'24</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>This year, NS-CUK successfully submitted two research papers to the AAAI, which is one of the most prestigious conferences in AI fields, and were accepted.</p> <p>The first paper, accepted into the main technical track, presents a novel structure-preserving graph transformer. This approach uniquely blends local and global structural features, significantly enhancing the performance in identifying graph structures. Details of this paper are as follows:</p> <ul> <li>Van Thuy Hoang, O-Joun Lee: Transitivity-Preserving Graph Representation Learning for Bridging Local Connectivity and Role-based Similarity. The 38th AAAI Conference on Artificial Intelligence (AAAI 2024), Vancouver, Canada; 02/2024.</li> </ul> <p>The second paper, submitted to the Explainable Machine Learning for Sciences Workshop (XAI4Sci) in conjunction with AAAI 2024, explores the application of explainable graph neural networks in atmospheric state estimation. This research focuses on assessing the importance of meteorological observations for accurate predictions. The paper details are:</p> <ul> <li>Hyeon-Ju Jeon, Jeon-Ho Kang, In-Hyuk Kwon, O-Joun Lee: Explainable Graph Neural Networks for Observation Impact Analysis in Atmospheric State Estimation. The Explainable Machine Learning for Sciences Workshop (XAI4Sci) held in conjunction with the 38th AAAI Conference on Artificial Intelligence (AAAI 2024), Vancouver, Canada; 02/2024.</li> </ul> <p align="center"><img src="/images/AAAI2024.jpg" style="width : 100%; max-width: 100%"></p> <p class="post-meta"> 1 min read   ·   December 09, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/12/01/cfp/" target="_blank" rel="external nofollow noopener">CFP of CUK AI Colloquium 2023</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <blockquote> <p>Call for Papers of the 2nd CUK Annual Colloquium on Artificial Intelligence</p> </blockquote> <blockquote> <p>(CUK AI Colloquium 2023; 제 2회 가톨릭대학교 인공지능 콜로키움)</p> </blockquote> <hr> <h2 id="aims-and-scope">Aims and Scope</h2> <p>The CUK Annual Colloquium on Artificial Intelligence is an esteemed workshop series hosted by the Department of Artificial Intelligence at the Catholic University of Korea. This event uniquely gathers both graduate and undergraduate students to showcase their research and engage in meaningful discussions with seasoned experts in the AI field. The 2023 colloquium promises a rich learning experience, featuring keynote speeches and panel discussions covering various topics. These range from career pathways in academia, industry, and entrepreneurship to cutting-edge developments in AI research.</p> <p>A highlight of the colloquium includes intensive, interactive mentoring sessions. These sessions are designed to facilitate collaborative and constructive dialogues between attendees and senior academic mentors. The focus is on research methodologies, career objectives, and fostering a vibrant, cooperative research community.</p> <hr> <h2 id="keynote-speeches">Keynote Speeches</h2> <h4 id="prof-buru-chang-sogang-university-rep-of-korea-서강대학교-장부루-교수">Prof. Buru Chang, Sogang University, Rep. of Korea <br>(서강대학교 장부루 교수)</h4> <ul> <li>Topic: Mitigating Hallucination in Multimodal Language Model via Reinforcement Learning</li> <li>Abstract: 이미지와 텍스트를 함께처리할 수 있는 Multimodal Language Model이 가진 Hallucination 문제를 완화하기 위한 강화학습 프레임워크를 소개한다.</li> </ul> <h4 id="dr-kyung-rae-kim-samsung-research-rep-of-korea-삼성리서치-김경래-책임연구원">Dr. Kyung-Rae Kim, Samsung Research, Rep. of Korea <br>(삼성리서치 김경래 책임연구원)</h4> <ul> <li>Topic: Using smart wearable ECG devices to develop deep learning-based multi-channel sleep classification technology</li> <li>Abstract: In the modern world, many people suffer from sleep deprivation due to stress, study, and work, and with the proliferation of computers and smartphones, sleep quality tends to decline. This has led to an increase in hospital visits for sleep disorders. Sleep has a significant impact on health and quality of life, and to monitor it, multi-channel biosignal-based automatic sleep stage classification devices and methods are being researched. In this paper, we propose a deep learning framework with optimal sleep stage classification performance by utilising ECG, accelerometer and gyro sensors for data-driven interpretation of sleep stages and various sampling techniques.</li> </ul> <h4 id="dr-jaehwan-jahng-kasan-ip-rep-of-korea-특허법인-가산-장재환-변리사">Dr. Jaehwan Jahng, Kasan IP, Rep. of Korea <br>(특허법인 가산 장재환 변리사)</h4> <ul> <li>Topic: 연구자가 알아야 할 특허 제도: 좋은 논문과 좋은 특허</li> <li>Abstract: 연구 성과를 제도적으로 보호받기 위해서는 논문 또는 학회를 통한 발표뿐만 아니라 특허 출원도 진행되어야 한다. 한편, 논문의 경우는 연구가 완성될 것을 요구하지만, 특허의 경우 당장 결과가 완성되지 않았더라도, 실현 가능성이 있는 아이디어만 있다면 출원할 수 있다. 그리고, 특허 제도의 특성상 소위 “좋은 논문”을 위한 연구를 할 때 주안점을 두어야 하는 부분과, “좋은 특허”를 위한 아이디어를 낼 때 주안점을 두어야 하는 부분은 다르다. 이번 강의에서는 특허 제도에 대한 간단한 소개와 함께, 논문을 위한 연구를 특허 출원으로 이어나가고자 할 때 유의해야 할 점들, 특히 인공지능 분야에서 학술적으로 좋은 연구 결과와 특허적으로 좋은 아이디어의 공통점과 차이점을 살펴보고자 한다.</li> </ul> <hr> <h2 id="submissions">Submissions</h2> <p>We invite papers with the following author instructions:</p> <ul> <li>All authors have to submit extended abstracts (Maximum 1 page, excluding references) with a corresponding A2-sized poster.</li> <li>A concise 5-minute presentation is required for all presenters.</li> </ul> <p>All submissions must adhere to the LNCS (Lecture Notes in Computer Science) formatting guidelines and be submitted as PDF files via email to:</p> <ul> <li><a href="mailto:ojlee@catholic.ac.kr"><img src="https://img.shields.io/badge/Organizer-ojlee@catholic.ac.kr-0C2E86?style=flat-square&amp;logo=Gmail&amp;logoColor=FFFFFF" alt="E-mail"></a></li> </ul> <hr> <h2 id="important-datestentative-schedule">Important Dates/Tentative Schedule</h2> <ul> <li>Submission deadline: Dec 15th, 2023</li> <li>Acceptance Notification: Dec 22nd, 2023</li> <li>Presentation Materials Due: Dec 24th, 2023</li> <li>Final Manuscript Due: Dec 24th, 2023</li> <li>Colloquium: Dec 27th, 2023</li> </ul> <hr> <h2 id="venue">Venue</h2> <div class="gmap"> <p align="center"><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d791.4723252778355!2d126.80200158589973!3d37.48693857838225!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x357b62c22341bd79%3A0x13730f14a1fc72e!2z6rCA7Yao66at64yA7ZWZ6rWQIOyEseyLrOq1kOyglQ!5e0!3m2!1sko!2skr!4v1651584191104!5m2!1sko!2skr" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe></p> </div> <p><br></p> <ul> <li>Sophie Barat Hall B351, Songsim Global Campus, The Catholic University of Korea <ul> <li>43, Jibong-ro, Bucheon, Gyeonggi-do 14662, Republic of Korea</li> </ul> </li> </ul> <hr> <p align="center"><a href="https://cukai.catholic.ac.kr/cukai/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/AI_Logo.png" style="width : 110px; margin : 15px"></a><a href="https://linc.catholic.ac.kr/lincplus/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/CUKLINK_Logo.jpg" style="width : 380px; margin : 10px; max-width: 90%"></a></p> <hr> <p class="post-meta"> 1 min read   ·   December 01, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2023/11/22/WS/" target="_blank" rel="external nofollow noopener">NS-CUK Winter School on Digital Humanities 2023</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <blockquote> <p>The 1st NS-CUK Winter School on Digital Humanities</p> </blockquote> <blockquote> <p>(NS-CUK DH 2023; 2023년 가톨릭대학교 디지털인문학 겨울학교)</p> </blockquote> <hr> <p>NS Lab@CUK organizes a winter school dedicated to digital humanities. This program consists of 9 lectures presented by Dr. Eun-Soon You (유은순 박사), and is scheduled to take place over a period of two weeks, from December 18th, 2023, to December 29th, 2023.</p> <p>Here are the details of the winter school:</p> <ul> <li>Location: Sophie Barat Hall B352, Songsim Global Campus, The Catholic University of Korea</li> <li>Time: Weekdays, 10:00</li> <li>TA: <a href="https://nslab-cuk.github.io/member/hbkim" rel="external nofollow noopener" target="_blank">Ho Beom Kim</a> </li> </ul> <hr> <h3 class="no_toc" id="programme-at-a-glance">Programme at a glance</h3> <details> <summary>Dec 18th, 2023: The meeting of humanities and technology, the beginning of convergence</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/COJtYLPUgc3uLT?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 19th, 2023: Theoretical Foundations of Digital Humanities: History, Concepts, and Necessity</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/p8lDoGrcnpmwtI?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 20th, 2023: New reading methods in the digital age: Franco Moretti’s ‘distant reading’ and Katherine Hayles’s ‘machine reading’</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/wvCfFnSgiilMGB?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 21st, 2023: Eyes to read data, humanities knowledge in the digital age</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/j8IRhR5lksZA7f?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 22nd, 2023: Digital analysis tools for humanities: Massive text analysis using ‘Google Ngram Viewer’</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/4NwUmooJi62roJ?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 26th, 2023: Digital analysis tools for humanities: Analyze movie reviews using big data analysis tool ‘Textom’</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/CMvkB7p0g6hUBU?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 27th, 2023: Digital analysis tools for humanities: Text analysis using Linguistic Inquiry and Word Count (LIWC)</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/uqp9W6difk1dBj?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 28th, 2023: The meeting of literature, technology, and design: Nicolas Ragonneau ‘Le Proustographe’</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/t1bHUMhao8X2JM?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <details class="no_toc"> <summary>Dec 29th, 2023: The meeting of literature, technology, and design: Albert Camus’ Digital Literature House</summary> <p align="center"><iframe src="https://www.slideshare.net/slideshow/embed_code/key/x9gewJmGozglxI?hostedIn=slideshare&amp;page=upload" width="90%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""></iframe></p> </details> <hr> <p align="center"><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/Logo_Square.png" style="width : 120px; margin : 10px"></a><a href="https://cukai.catholic.ac.kr/cukai/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/AI_Logo.png" style="width : 110px; margin : 15px"></a><a href="https://linc.catholic.ac.kr/lincplus/index.html" rel="external nofollow noopener" target="_blank"><img align="center" src="/images/CUKLINK_Logo.jpg" style="width : 380px; margin : 10px"></a></p> <hr> <p class="post-meta"> 1 min read   ·   November 22, 2023   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/3/" tabindex="-1" aria-disabled="3">Newer</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/2/index.html" title="blog - page 2">2</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a> </li> <li class="page-item active"> <a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/5/">Older</a> </li> </ul> </nav> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 O-Joun Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Affiliated with <a href="https://nslab-cuk.github.io/" target="_blank" rel="external nofollow noopener">Network Science Lab @ CUK</a>. Last updated: April 04, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>