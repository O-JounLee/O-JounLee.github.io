<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> blog | O-Joun Lee </title> <meta name="author" content="O-Joun Lee"> <meta name="description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="O-Joun Lee"> <meta property="og:type" content="website"> <meta property="og:title" content="O-Joun Lee | blog"> <meta property="og:url" content="https://o-jounlee.github.io/blog/"> <meta property="og:description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="blog"> <meta name="twitter:description" content="The academic profile of Prof. O-Joun Lee at The Catholic University of Korea "> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "O-Joun Lee"
        },
        "url": "https://o-jounlee.github.io/blog/index.html",
        "@type": "WebSite",
        "description": "The academic profile of Prof. O-Joun Lee at The Catholic University of Korea
",
        "headline": "blog",
        
        "sameAs": ["https://orcid.org/0000-0001-8921-5443", "https://scholar.google.com/citations?user=43GFjoYAAAAJ", "https://www.semanticscholar.org/author/144914730", "https://www.scopus.com/authid/detail.uri?authorId=57150108800", "https://github.com/NSLab-CUK", "https://nslab-cuk.github.io/", "https://dblp.uni-trier.de/pid/160/1579.html", "https://www.kaggle.com/cuknslab"],
        
        "name": "O-Joun Lee",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://o-jounlee.github.io/blog/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">O-Joun</span> Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <div class="header-bar"> <h1>O-Joun Lee</h1> <h2>Graphs illustrate intricate patterns in our perception of the world and ourselves; graph mining enhances this comprehension by highlighting overlooked details.</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>•</p> <li> <i class="fa-solid fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>•</p> <li> <i class="fa-solid fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <ul class="post-list"> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2025/03/10/Award/" target="_blank" rel="external nofollow noopener">Van Thuy Hoang won the Best Award in the 22nd Graduate School Academic Awards</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>The Catholic University of Korea (CUK) announced that Van Thuy Hoang, a Ph.D. candidate in the Department of Artificial Intelligence, has been awarded the Best Award (최우수상) at the 22nd Graduate School Academic Awards (제22회 대학원 학술상) Ceremony. Mr. Hoang was recognized for his outstanding research achievements in the field of graph learning and recommendation systems​. This prestigious honor highlights the excellence of his work and his significant contributions to advancing artificial intelligence at CUK and beyond.</p> <p>Mr. Hoang’s research focuses on graph-based machine learning, where he has developed novel graph neural network models that push the boundaries of graph representation learning. Notably, his work introduced the “Unified Graph Transformer,” a model that effectively integrates local and global network information to learn powerful graph representations. This approach achieved state-of-the-art performance on numerous benchmark datasets​ and was presented at the AAAI 2024 conference, underscoring the impact and international recognition of his research​. In addition, he has applied graph learning to intelligent recommendation systems, designing knowledge graph-driven frameworks for real-world applications – for example, a halal cosmetic recommendation system that leverages complex relationships between products and ingredients to improve cultural relevance in recommendations​.</p> <p>At the 22nd Graduate School Academic Awards Ceremony, Mr. Hoang’s accomplishments earned the event’s top honor, the Best Award. This award is bestowed on the most distinguished graduate research contributions, and Mr. Hoang’s selection reflects the high esteem in which his work is held within the academic community. The recognition not only celebrates his individual excellence but also emphasizes the importance of graph-based AI research as a critical area of innovation at CUK. Mr. Hoang’s success serves as an inspiration to fellow researchers and highlights the growing impact of artificial intelligence and network science in addressing complex real-world challenges.</p> <p>As the home of this achievement, CUK’s Network Science Lab has established itself as a leader in graph-based AI and machine learning research. Under the guidance of Prof. O-Joun Lee, the lab has pioneered cutting-edge graph learning methodologies and applied them to real-world domains, covering innovations such as advanced recommendation systems for offline retail environments​ and novel graph neural network models for molecular structure learning in chemistry​. The lab’s comprehensive approach – bridging theoretical innovation with interdisciplinary collaboration – demonstrates how graph learning can drive the next generation of AI solutions. Together, Mr. Hoang and the Network Science Lab are shaping the future of AI, exemplifying innovation and impact through network science.</p> <p align="center"><img src="/images/250227_Recipients.jpg" style="width : 90%; max-width: 90%"></p> <p align="center"><img src="/images/250227_Awards.jpg" style="width : 90%; max-width: 90%"></p> <p class="post-meta"> 1 min read   ·   March 10, 2025   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2025/02/28/AAAI25/" target="_blank" rel="external nofollow noopener">One NS-CUK paper presented at AAAI'25</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>Our team member, <a href="https://nslab-cuk.github.io/member/hoangvanthuy90" rel="external nofollow noopener" target="_blank">Van Thuy Hoang</a>, presented his paper, which is titled “Pre-training Graph Neural Networks on Molecules by using Subgraph-conditioned Graph Information Bottleneck” and depicts his novel molecular graph neural network pre-training method called “<a href="https://github.com/NSLab-CUK/S-CGIB" rel="external nofollow noopener" target="_blank">Subgraph-conditioned Graph Information Bottleneck (S-CGIB)</a>,” at <a href="https://aaai.org/aaai-conference/" rel="external nofollow noopener" target="_blank">the 39th AAAI Conference on Artificial Intelligence (AAAI 2025)</a>. This recognition demonstrated his dedication and expertise in graph learning.</p> <ul> <li>Van Thuy Hoang, O-Joun Lee: Pre-training Graph Neural Networks on Molecules by using Subgraph-conditioned Graph Information Bottleneck. The 39th AAAI Conference on Artificial Intelligence (AAAI 2025), Philadelphia, PA, USA; 02/2025.</li> </ul> <iframe width="1280" height="720" src="https://www.youtube.com/embed/o6dW0dbayb8" title="Van Thuy Hoang: Pre-training Graph Neural Networks on Molecules | AAAI 2025 (Extended Version)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><br></p> <p align="center"><img src="/images/AAAI2025_poster_Thuy_Extended.webp" style="width : 90%; max-width: 90%"></p> <p align="center"><img src="/images/250228_01.jpg" style="width : 90%; max-width: 90%"></p> <p align="center"><img src="/images/250228.jpg" style="width : 90%; max-width: 90%"></p> <p align="center"><img src="/images/250228_02.jpg" style="width : 90%; max-width: 90%"></p> <hr> <p align="center"><img src="/images/AAAI2025.jpg" style="width : 100%; max-width: 100%"></p> <p class="post-meta"> 1 min read   ·   February 28, 2025   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2025/01/08/HaCKG/" target="_blank" rel="external nofollow noopener">Halal or Not, A Novel GNN Model for Predicting Cultural Appropriateness of Everyday Products</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>We present <a href="https://github.com/NSLab-CUK/Halal-or-Not" rel="external nofollow noopener" target="_blank">HaCKG</a>, a novel GNN model for analyzing ingredients of everyday products to predict their cultural availability, e.g. predicting whether food or cosmetics meet halal or vegan criteria. HaCKG is developed by NS Lab, CUK, based on pure PyTorch backend.</p> <p align="center"> <img src="/images/HaCKG.jpg" alt="LiteralKG Architecture" width="800"> <br> <b></b> The overall architecture of LiteralKG. </p> <p>The growing demand for halal cosmetic products has exposed significant challenges, especially in Muslimmajority countries. Recently, various machine learning-based strategies, e.g., image-based methods, have shown remarkable success in predicting the halal status of cosmetics. However, these methods mainly focus on analyzing the discrete and specific ingredients within separate cosmetics, which ignore the high-order and complex relations between cosmetics and ingredients. To address this problem, we propose a halal cosmetic recommendation framework, namely HaCKG, that leverages a knowledge graph of cosmetics and their ingredients to explicitly model and capture the relationships between cosmetics and their components. By representing cosmetics and ingredients as entities within the knowledge graph, HaCKG effectively learns the high-order and complex relations between entities, offering a robust method for predicting halal status. Specifically, we first construct a cosmetic knowledge graph representing the relations between various cosmetics, ingredients, and their properties. We then propose a pre-trained relational graph attention network model with residual connections to learn the structural relation between entities in the knowledge graph. The pre-trained model is then fine-tuned on downstream cosmetic data to predict halal status. Extensive experiments on the cosmetic dataset over halal prediction tasks demonstrate the superiority of our model over state-of-the-art baselines.</p> <h2 id="a-short-description-of-hackg">A short description of <strong>HaCKG</strong>:</h2> <ul> <li>We construct a cosmetic knowledge graph that represents the natural relations between cosmetic products, ingredients, and the ingredient’s properties. The knowledge graph then can serve as a fundamental tool for our model to learn cosmetic relations and predict the halal status.</li> <li>The main core of HaCKG is a pre-trained residual Graph Attention Network (r-GAT) that incorporates residual connections to capture relationships between entities in the cosmetic knowledge graph effectively in the context of Self-Supervised Learning. The pre-training strategy enables r-GAT to learn the structural relationships among cosmetics, ingredients, and their properties without relying on label information.</li> <li>We conduct extensive experiments on halal cosmetic product datasets. The significant improvements demonstrate the superiority of our proposed model compared to state-of-the-art baselines.</li> </ul> <h2 id="the-hackg-is-available-at">The <strong>HaCKG</strong> is available at:</h2> <ul> <li><a href="https://github.com/NSLab-CUK/Halal-or-Not" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/GitHub-Data%20&amp;%20Code-9B9B9B?style=flat-square&amp;logo=GitHub" alt="GitHub"></a></li> <li><a href="https://arxiv.org/abs/2501.05768" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.05768-b31b1b?style=flat-square&amp;logo=arxiv&amp;logoColor=red" alt="arXiv"></a></li> <li><a href="https://doi.org/10.1109/ACCESS.2025.3528488" rel="external nofollow noopener" target="_blank"><img src="http://img.shields.io/:DOI-10.1109/ACCESS.2025.3528488-FAB70C?style=flat-square&amp;logo=doi" alt="DOI"></a></li> </ul> <h2 id="cite-hackg-as">Cite “<strong>HaCKG</strong>” as:</h2> <p>Please cite our <a href="https://doi.org/10.1109/ACCESS.2025.3528488" rel="external nofollow noopener" target="_blank">paper</a> if you find <em>HaCKG</em> useful in your work:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@Article{Hoang2023,
  author  = {Van Thuy Hoang and Tien-Bach-Thanh Do and Jinho Seo and Seung Charlie Kim and Luong Vuong Nguyen and Duong Nguyen Minh Huy and Hyeon-Ju Jeon and O-Joun Lee},
  title   = {Halal or Not: Knowledge Graph Completion for Predicting Cultural Appropriateness of Daily Products},
  journal = {IEEE Access},
  year    = {2025},
  volume  = {},
  pages   = {},
  month   = jan,
  issn    = {2169-3536},
  doi     = {10.1109/ACCESS.2025.3528488},
}
</code></pre></div></div> <p><img class="emoji" title=":page_facing_up:" alt=":page_facing_up:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c4.png" height="20" width="20"><img class="emoji" title=":woman_technologist:" alt=":woman_technologist:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f469-1f4bb.png" height="20" width="20"><img class="emoji" title=":bookmark_tabs:" alt=":bookmark_tabs:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d1.png" height="20" width="20"><img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"><img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20"></p> <h2 id="contributors">Contributors:</h2> <p><a href="https://github.com/NSLab-CUK/Unified-Graph-Transformer/graphs/contributors" rel="external nofollow noopener" target="_blank"> <img src="https://contrib.rocks/image?repo=NSLab-CUK/Unified-Graph-Transformer"> </a></p> <hr> <p><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img src="https://github.com/NSLab-CUK/NSLab-CUK/raw/main/Logo_Dual_Wide.png"></a></p> <hr> <p class="post-meta"> 1 min read   ·   January 08, 2025   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2024/12/19/SCGIB/" target="_blank" rel="external nofollow noopener">S-CGIB, A Novel Pre-trained Graph Neural Network Model in Molecular Structure Learning</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>We present <a href="https://github.com/NSLab-CUK/S-CGIB" rel="external nofollow noopener" target="_blank">S-CGIB</a>, a novel Architecture for Pre-training Graph Neural Networks in Molecular Structure Learning and developed by NS Lab, CUK based on pure PyTorch backend. The paper has been accepted for presentation at the AAAI 2025 conference.</p> <p align="center"> <img src="/images/SCGIB.jpg" alt="Subgraph-conditioned Graph Information Bottleneck" width="800"> <br> <b></b> The overall architecture of Subgraph-conditioned Graph Information Bottleneck. </p> <p>We aim to build a pre-trained Graph Neural Network (GNN) model on molecules without human annotations or prior knowledge. Although various attempts have been proposed to overcome limitations in acquiring labeled molecules, the previous pre-training methods still rely on semantic subgraphs, i.e., functional groups. Only focusing on the functional groups could overlook the graph-level distinctions. The key challenge to build a pre-trained GNN on molecules is how to (1) generate well-distinguished graph-level representations and (2) automatically discover the functional groups without prior knowledge. To solve it, we propose a novel Subgraph-conditioned Graph Information Bottleneck, named S-CGIB, for pre-training GNNs to recognize core subgraphs (graph cores) and significant subgraphs. The main idea is that the graph cores contain compressed and sufficient information that could generate well-distinguished graph-level representations and reconstruct the input graph conditioned on significant subgraphs across molecules under the S-CGIB principle. To discover significant subgraphs without prior knowledge about functional groups, we propose generating a set of functional group candidates, i.e., ego networks, and using an attention-based interaction between the graph core and the candidates. Despite being identified from self-supervised learning, our learned subgraphs match the real-world functional groups. Extensive experiments on molecule datasets across various domains demonstrate the superiority of S-CGIB.</p> <h2 id="a-short-description-of-s-cgib">A short description of S-CGIB:</h2> <ul> <li>S-CGIB is trained to generate well-distinguished graph-level representations and automatically capture significant subgraphs without explicit annotations or prior knowledge in the context of Self-Supervised Learning. The fundamental idea behind our strategy is that, across the chemical domain, molecules share universal core subgraphs that can combine with specific significant subgraphs to robust representations of molecules.</li> <li>S-CGIB generates well-distinguished graph-level representations by compressing an input molecule graph into a graph core conditioned on specific significant subgraphs without using label information under the Subgraph-conditioned Graph Information Bottleneck principle.</li> <li>S-CGIB discover the significant subgraphs (functional groups) from the subgraph candidates (ego networks rooted at each node) through the attention-based interaction between the graph core and the ego networks under the graph reconstruction.</li> <li>Extensive experiments on molecule datasets across four domains demonstrate the superiority of S-CGIB.</li> </ul> <h2 id="the-s-cgib-is-available-at">The S-CGIB is available at:</h2> <ul> <li><a href="https://github.com/NSLab-CUK/S-CGIB" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/GitHub-Data%20&amp;%20Code-9B9B9B?style=flat-square&amp;logo=GitHub" alt="GitHub"></a></li> <li><a href="https://arxiv.org/abs/2412.15589" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/arXiv-2412.15589-b31b1b?style=flat-square&amp;logo=arxiv&amp;logoColor=red" alt="arXiv"></a></li> <li><a href="https://paperswithcode.com/paper/pre-training-graph-neural-networks-on" rel="external nofollow noopener" target="_blank"><img src="https://custom-icon-badges.demolab.com/badge/Papers%20With%20Code-S--CGIB-21CBCE?style=flat-square&amp;logo=paperswithcode" alt="PwC"></a></li> </ul> <h2 id="cite-s-cgib-as">Cite “S-CGIB” as:</h2> <p>Please cite our <a href="https://arxiv.org/abs/2412.15589" rel="external nofollow noopener" target="_blank">paper</a> if you find <em>S-CGIB</em> useful in your work:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@misc{hoang2024pretraininggraphneuralnetworks,
      title={Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck}, 
      author={Van Thuy Hoang and O-Joun Lee},
      year={2024},
      eprint={2412.15589},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.15589}, 
}
</code></pre></div></div> <p><img class="emoji" title=":page_facing_up:" alt=":page_facing_up:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4c4.png" height="20" width="20"><img class="emoji" title=":woman_technologist:" alt=":woman_technologist:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f469-1f4bb.png" height="20" width="20"><img class="emoji" title=":bookmark_tabs:" alt=":bookmark_tabs:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d1.png" height="20" width="20"><img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"><img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20"></p> <h2 id="contributors">Contributors:</h2> <p><a href="https://github.com/NSLab-CUK/Unified-Graph-Transformer/graphs/contributors" rel="external nofollow noopener" target="_blank"> <img src="https://contrib.rocks/image?repo=NSLab-CUK/Unified-Graph-Transformer"> </a></p> <hr> <p><a href="https://nslab-cuk.github.io/" rel="external nofollow noopener" target="_blank"><img src="https://github.com/NSLab-CUK/NSLab-CUK/raw/main/Logo_Dual_Wide.png"></a></p> <hr> <p class="post-meta"> 1 min read   ·   December 19, 2024   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> </p> </li> <li> <h3> <a class="post-title" href="https://nslab-cuk.github.io/2024/12/09/AAAI25/" target="_blank" rel="external nofollow noopener">One NS-CUK paper accepted for AAAI'25</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p></p> <p>This year, NS-CUK successfully submitted one research paper to the AAAI, which is one of the most prestigious conferences in AI fields, and was accepted.</p> <p>This paper, accepted into the main technical track, presents a novel method for pre-training graph neural networks on molecules. Details of this paper are as follows:</p> <ul> <li>Van Thuy Hoang, O-Joun Lee: Pre-training Graph Neural Networks on Molecules by using Subgraph-conditioned Graph Information Bottleneck. The 39th AAAI Conference on Artificial Intelligence (AAAI 2025), Philadelphia, PA, USA; 02/2025.</li> </ul> <p align="center"><img src="/images/AAAI2025.jpg" style="width : 100%; max-width: 100%"></p> <p class="post-meta"> 1 min read   ·   December 09, 2024   ·   Network Science Lab @ CUK </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> </p> </li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item disabled"> <a class="page-link" href="" tabindex="-1" aria-disabled="">Newer</a> </li> <li class="page-item active"> <a class="page-link" href="/blog/index.html" title="blog">1</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/2/index.html" title="blog - page 2">2</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a> </li> <li class="page-item "> <a class="page-link" href="/blog/page/2/">Older</a> </li> </ul> </nav> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 O-Joun Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Affiliated with <a href="https://nslab-cuk.github.io/" target="_blank" rel="external nofollow noopener">Network Science Lab @ CUK</a>. Last updated: April 04, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>